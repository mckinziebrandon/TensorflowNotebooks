{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant(10, name=\"a\")\n",
    "b = tf.constant(90, name=\"b\")\n",
    "y = tf.Variable(a + 2 * b, name=\"y\")\n",
    "\n",
    "model = tf.initialize_all_variables()\n",
    "with tf.Session() as session:\n",
    "    merged = tf.merge_all_summaries()\n",
    "    writer = tf.train.SummaryWriter\\\n",
    "    (\"/tmp/tensorflowlogs\", session.graph)\n",
    "    session.run(model)\n",
    "    print(session.run(y))\n",
    "    \n",
    "# Open terminal and run command:\n",
    "# tensorboard --logdir=/tmp/tensorflowlogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Convolutional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_input, n_classes = 784, 10\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate  = 1e-3\n",
    "training_iters = 1e5\n",
    "batch_size     = 128\n",
    "display_step   = 10\n",
    "dropout        = 0.75 # dropout probability\n",
    "keep_prob = tf.placeholder(tf.float32) # (for dropout)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "_X = tf.reshape(x, shape=[-1, 28, 28, 1])  # Assuming -1 will be the number of samples?\n",
    "y = tf.placeholder(tf.float32, [None, n_classes]) # output probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def conv2d(img, w, b):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        img --  input tensor of shape [batchsize, in_height, in_width, in_channels]\n",
    "                where channels may be, e.g. 3 for RGB color\n",
    "        w   --  filter with shape [f_height, f_width, in_channels, n_feat_maps]\n",
    "        b   --  bias for each feature map (number of biases = depth of the conv layer)\n",
    "    \"\"\"\n",
    "    return tf.nn.relu(tf.nn.bias_add(\\\n",
    "            tf.nn.conv2d(img, w, strides=[1,1,1,1], padding='SAME'), b))\n",
    "\n",
    "def max_pool(img, k=2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img -- output of a conv layer\n",
    "        k   -- window size and stride (small)\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(img, \n",
    "                         ksize=[1, k, k, 1], \n",
    "                         strides=[1, k, k, 1], \n",
    "                         padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# __________ Weights and biases for all layers __________\n",
    "\n",
    "# 5x5 conv, 1 input, 32 outputs\n",
    "wc1 = tf.Variable(tf.random_normal([5, 5, 1, 32])) \n",
    "bc1 = tf.Variable(tf.random_normal([32]))\n",
    "\n",
    "# 5x5 conv, 32 inputs, 64 outputs\n",
    "wc2 = tf.Variable(tf.random_normal([5, 5, 32, 64])) \n",
    "bc2 = tf.Variable(tf.random_normal([64]))\n",
    "\n",
    "# FC, 7*7*64 inputs, 1024 outputs\n",
    "wd1 = tf.Variable(tf.random_normal([7*7*64, 1024]))\n",
    "bd1 = tf.Variable(tf.random_normal([1024]))\n",
    "\n",
    "# Output layer. 1024 inputs, 10 outputs.\n",
    "wout = tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "bout = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# __________ The layers __________\n",
    "\n",
    "# [In] --> Conv --> Pool --> Dropout\n",
    "conv1 = conv2d(_X, wc1, bc1)\n",
    "conv1 = max_pool(conv1, k=2)\n",
    "conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "\n",
    "# --> Conv --> Pool --> Dropout\n",
    "conv2 = conv2d(conv1, wc2, bc2)\n",
    "conv2 = max_pool(conv2, k=2)\n",
    "conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "\n",
    "# --> Fully-Connected[ReLu] --> Dropout\n",
    "# (reshape conv2 out essentially by flattening all maps into single list)\n",
    "dense1 = tf.reshape(conv2, [-1, wd1.get_shape().as_list()[0]])\n",
    "dense1 = tf.nn.relu( tf.add( tf.matmul( dense1, wd1 ), bd1 ) )\n",
    "dense1 = tf.nn.dropout(dense1, keep_prob)\n",
    "\n",
    "# Output prediction.\n",
    "pred = tf.add(tf.matmul(dense1, wout), bout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost and Optimizing\n",
    "\n",
    "$$\n",
    "\\text{cost} = \\frac{1}{n} \\sum_{i = 1}^{n_{out}} y_i \\log\\bigg( \\frac{e^{z_i}}{\\sum_k e^{z_k}}\\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ______________ Training _______\n",
    "cost      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# _______ Evaluation _____\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy     = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iter', 1280, ', Minibatch Loss=25021.994141', ', Training Accuracy=0.26562')\n",
      "('Iter', 2560, ', Minibatch Loss=20956.230469', ', Training Accuracy=0.41406')\n",
      "('Iter', 3840, ', Minibatch Loss=10467.468750', ', Training Accuracy=0.54688')\n",
      "('Iter', 5120, ', Minibatch Loss=6931.669434', ', Training Accuracy=0.64844')\n",
      "('Iter', 6400, ', Minibatch Loss=11381.146484', ', Training Accuracy=0.58594')\n",
      "('Iter', 7680, ', Minibatch Loss=6931.756836', ', Training Accuracy=0.67188')\n",
      "('Iter', 8960, ', Minibatch Loss=6043.289062', ', Training Accuracy=0.70312')\n",
      "('Iter', 10240, ', Minibatch Loss=2950.967041', ', Training Accuracy=0.78906')\n",
      "('Iter', 11520, ', Minibatch Loss=4387.661133', ', Training Accuracy=0.79688')\n",
      "('Iter', 12800, ', Minibatch Loss=4279.759277', ', Training Accuracy=0.78125')\n",
      "('Iter', 14080, ', Minibatch Loss=2511.234863', ', Training Accuracy=0.84375')\n",
      "('Iter', 15360, ', Minibatch Loss=3200.528809', ', Training Accuracy=0.79688')\n",
      "('Iter', 16640, ', Minibatch Loss=2861.273438', ', Training Accuracy=0.82031')\n",
      "('Iter', 17920, ', Minibatch Loss=2214.196289', ', Training Accuracy=0.88281')\n",
      "('Iter', 19200, ', Minibatch Loss=989.559265', ', Training Accuracy=0.90625')\n",
      "('Iter', 20480, ', Minibatch Loss=4211.814941', ', Training Accuracy=0.78906')\n",
      "('Iter', 21760, ', Minibatch Loss=1644.427979', ', Training Accuracy=0.91406')\n",
      "('Iter', 23040, ', Minibatch Loss=2109.490967', ', Training Accuracy=0.87500')\n",
      "('Iter', 24320, ', Minibatch Loss=2386.041504', ', Training Accuracy=0.83594')\n",
      "('Iter', 25600, ', Minibatch Loss=1501.948364', ', Training Accuracy=0.88281')\n",
      "('Iter', 26880, ', Minibatch Loss=2240.972656', ', Training Accuracy=0.82812')\n",
      "('Iter', 28160, ', Minibatch Loss=2119.425537', ', Training Accuracy=0.87500')\n",
      "('Iter', 29440, ', Minibatch Loss=2242.839844', ', Training Accuracy=0.82812')\n",
      "('Iter', 30720, ', Minibatch Loss=1093.348633', ', Training Accuracy=0.88281')\n",
      "('Iter', 32000, ', Minibatch Loss=1532.251099', ', Training Accuracy=0.88281')\n",
      "('Iter', 33280, ', Minibatch Loss=985.126221', ', Training Accuracy=0.88281')\n",
      "('Iter', 34560, ', Minibatch Loss=1191.394165', ', Training Accuracy=0.90625')\n",
      "('Iter', 35840, ', Minibatch Loss=2769.808105', ', Training Accuracy=0.82812')\n",
      "('Iter', 37120, ', Minibatch Loss=451.285889', ', Training Accuracy=0.94531')\n",
      "('Iter', 38400, ', Minibatch Loss=857.569580', ', Training Accuracy=0.89844')\n",
      "('Iter', 39680, ', Minibatch Loss=2352.155762', ', Training Accuracy=0.88281')\n",
      "('Iter', 40960, ', Minibatch Loss=1384.690674', ', Training Accuracy=0.90625')\n",
      "('Iter', 42240, ', Minibatch Loss=828.415405', ', Training Accuracy=0.92188')\n",
      "('Iter', 43520, ', Minibatch Loss=437.712341', ', Training Accuracy=0.95312')\n",
      "('Iter', 44800, ', Minibatch Loss=584.637817', ', Training Accuracy=0.89844')\n",
      "('Iter', 46080, ', Minibatch Loss=1383.199707', ', Training Accuracy=0.89062')\n",
      "('Iter', 47360, ', Minibatch Loss=1923.911255', ', Training Accuracy=0.88281')\n",
      "('Iter', 48640, ', Minibatch Loss=1327.275146', ', Training Accuracy=0.88281')\n",
      "('Iter', 49920, ', Minibatch Loss=450.466156', ', Training Accuracy=0.90625')\n",
      "('Iter', 51200, ', Minibatch Loss=461.589783', ', Training Accuracy=0.93750')\n",
      "('Iter', 52480, ', Minibatch Loss=512.834595', ', Training Accuracy=0.95312')\n",
      "('Iter', 53760, ', Minibatch Loss=1481.610840', ', Training Accuracy=0.85156')\n",
      "('Iter', 55040, ', Minibatch Loss=1503.613281', ', Training Accuracy=0.90625')\n",
      "('Iter', 56320, ', Minibatch Loss=663.131042', ', Training Accuracy=0.91406')\n",
      "('Iter', 57600, ', Minibatch Loss=836.979126', ', Training Accuracy=0.94531')\n",
      "('Iter', 58880, ', Minibatch Loss=1394.500244', ', Training Accuracy=0.92188')\n",
      "('Iter', 60160, ', Minibatch Loss=1150.654297', ', Training Accuracy=0.89062')\n",
      "('Iter', 61440, ', Minibatch Loss=884.085022', ', Training Accuracy=0.89844')\n",
      "('Iter', 62720, ', Minibatch Loss=641.650208', ', Training Accuracy=0.93750')\n",
      "('Iter', 64000, ', Minibatch Loss=612.565613', ', Training Accuracy=0.92188')\n",
      "('Iter', 65280, ', Minibatch Loss=1026.186890', ', Training Accuracy=0.88281')\n",
      "('Iter', 66560, ', Minibatch Loss=1012.022217', ', Training Accuracy=0.89844')\n",
      "('Iter', 67840, ', Minibatch Loss=538.746582', ', Training Accuracy=0.92969')\n",
      "('Iter', 69120, ', Minibatch Loss=2331.966064', ', Training Accuracy=0.85156')\n",
      "('Iter', 70400, ', Minibatch Loss=611.249207', ', Training Accuracy=0.92969')\n",
      "('Iter', 71680, ', Minibatch Loss=611.909607', ', Training Accuracy=0.94531')\n",
      "('Iter', 72960, ', Minibatch Loss=1363.580566', ', Training Accuracy=0.88281')\n",
      "('Iter', 74240, ', Minibatch Loss=996.121582', ', Training Accuracy=0.91406')\n",
      "('Iter', 75520, ', Minibatch Loss=730.850952', ', Training Accuracy=0.92969')\n",
      "('Iter', 76800, ', Minibatch Loss=781.747681', ', Training Accuracy=0.92969')\n",
      "('Iter', 78080, ', Minibatch Loss=854.089539', ', Training Accuracy=0.93750')\n",
      "('Iter', 79360, ', Minibatch Loss=1397.916870', ', Training Accuracy=0.88281')\n",
      "('Iter', 80640, ', Minibatch Loss=1405.003418', ', Training Accuracy=0.88281')\n",
      "('Iter', 81920, ', Minibatch Loss=806.627136', ', Training Accuracy=0.92188')\n",
      "('Iter', 83200, ', Minibatch Loss=647.945007', ', Training Accuracy=0.93750')\n",
      "('Iter', 84480, ', Minibatch Loss=1018.518982', ', Training Accuracy=0.93750')\n",
      "('Iter', 85760, ', Minibatch Loss=1204.980469', ', Training Accuracy=0.89062')\n",
      "('Iter', 87040, ', Minibatch Loss=743.574951', ', Training Accuracy=0.92188')\n",
      "('Iter', 88320, ', Minibatch Loss=638.823486', ', Training Accuracy=0.95312')\n",
      "('Iter', 89600, ', Minibatch Loss=549.751770', ', Training Accuracy=0.96094')\n",
      "('Iter', 90880, ', Minibatch Loss=727.560242', ', Training Accuracy=0.91406')\n",
      "('Iter', 92160, ', Minibatch Loss=624.963196', ', Training Accuracy=0.91406')\n",
      "('Iter', 93440, ', Minibatch Loss=1152.272461', ', Training Accuracy=0.85938')\n",
      "('Iter', 94720, ', Minibatch Loss=409.238037', ', Training Accuracy=0.95312')\n",
      "('Iter', 96000, ', Minibatch Loss=444.576447', ', Training Accuracy=0.92969')\n",
      "('Iter', 97280, ', Minibatch Loss=1209.410645', ', Training Accuracy=0.86719')\n",
      "('Iter', 98560, ', Minibatch Loss=217.887985', ', Training Accuracy=0.93750')\n",
      "('Iter', 99840, ', Minibatch Loss=469.807068', ', Training Accuracy=0.92969')\n",
      "Optimization finished. Am robot.\n"
     ]
    }
   ],
   "source": [
    "# _________ BLAST OFF _____________\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})\n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "            loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "            print(\"Iter\", step * batch_size, \n",
    "                 \", Minibatch Loss={:.6f}\".format(loss),\n",
    "                 \", Training Accuracy={:.5f}\".format(acc))\n",
    "        \n",
    "        step += 1\n",
    "    print(\"Optimization finished. Am robot.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
